---
title: 'BA02.[Phụ lục 1] Động cơ Bayes: Giả kim thuật toán học để quản lý sự bất định'
date: '2026-01-02'
tags: ['bayeaian', 'bayes', 'CRM', 'likelihood', 'Odds']
draft: false
summary: 'BA02.[Phụ lục 1] Động cơ Bayes: Giả kim thuật toán học để quản lý sự bất định'
images: ["/static/images/BA02_1.png"]
authors: ["default"]
---

 

# Chuyển đổi Trực giác thành Ngôn ngữ Toán học

Bài viết này giải thích các nguyên lý toán học của Động cơ Bayesian được đề cập trong tập [BA02](https://news.exavions.com/vi/ba02-suy-luan-bayesian-cua-exa-ban-tay-vo-hinh-cua-kinh-doanh-cuoc-danh-bac-60-ngay/) và tính hiệu quả của nó. Mục đích là để dự đoán chính xác xác suất thành công của việc bán hàng trong môi trường kinh doanh không chắc chắn. Về cốt lõi, nó đề cập đến quá trình rút ra các chỉ số ra quyết định tối ưu bằng cách kết hợp Phân phối Beta, giúp số hóa những kinh nghiệm trong quá khứ, và Phân phối Nhị thức, giúp nắm bắt các tín hiệu thời gian thực tại hiện trường. Đặc biệt, bài viết nhấn mạnh việc tối đa hóa tính thời gian thực và hiệu quả tính toán của hệ thống bằng cách sử dụng Phân phối Tiên nghiệm Liên hợp (Conjugate Prior), cho phép cập nhật ngay lập tức mà không cần các phép tính phức tạp. Ngoài ra, mô hình này áp dụng phương pháp Ước lượng Đệ quy (Recursive Estimation) để đưa ra phán đoán ngay lập tức mỗi khi dữ liệu phát sinh, đảm bảo tính hợp lệ về mặt kỹ thuật được tối ưu hóa cho kinh doanh hiện đại. Kết quả là, tài liệu này cho thấy rõ cách mô hình hóa toán học tinh vi chuyển đổi trực giác mơ hồ thành những thông tin chi tiết dựa trên dữ liệu đáng tin cậy.

Trong màn sương mù của kinh doanh, các giám đốc kinh doanh, nhà quản lý và ban điều hành, những người phải đưa ra quyết định, luôn cảm thấy khao khát. Họ khao khát câu trả lời cho câu hỏi: "Tỷ lệ thắng trong tình huống này ngay bây giờ là bao nhiêu phần trăm?". 'Động cơ Bayesian (Bayesian Engine)', trái tim của hệ thống Exa, dịch quá trình trừu tượng này thành ngôn ngữ tinh vi nhất: toán học.

Trong bài viết này, chúng tôi sẽ phân tích sâu các trụ cột toán học chống đỡ kiến trúc của động cơ này trong môi trường bán hàng hoặc các tình huống tương tự, và tại sao đây là 'giải pháp tối ưu' trong môi trường doanh nghiệp.

Mặt khác, các mô hình Bayesian dựa trên MCMC hoặc Deep Learning là tài sản vĩ đại của nhân loại để giải quyết các vấn đề phức tạp nhiều chiều. Tuy nhiên, việc nhấn mạnh rằng 'hiệu quả toán học' và 'sự minh bạch' mà Mô hình Beta-Nhị thức sở hữu là vũ khí mạnh nhất trong các lĩnh vực cụ thể như suy luận xác suất thành công bán hàng cũng là một cách để đảm bảo tính khách quan về mặt kỹ thuật.

Lưu ý: Động cơ AI của Exa sử dụng toán học Bayesian phù hợp theo từng tình huống riêng biệt. Vì các tình huống áp dụng rất đa dạng, hầu hết toán học Bayesian đều được áp dụng, và các công nghệ AI đã được kiểm chứng tại hiện trường như ML (Machine Learning), DL (Deep Learning), RL (Reinforcement Learning), và LLM (Generative AI) được huy động bên trong động cơ dựa trên nhu cầu kinh doanh. Bài viết này chỉ nhắm vào nội dung kỹ thuật của toán học được sử dụng trong tập phim về bán hàng.

Phản ánh bối cảnh này, trong khi tôn trọng lý do tồn tại của mỗi công nghệ, tôi dự định mô tả một cách logic tại sao các công nghệ được sử dụng trong tập này là 'Tiêu chuẩn Vàng (Golden Standard)' trong lĩnh vực này.

---

## 1. Số hóa Kinh nghiệm: 'Phân phối Beta' dưới dạng Phân phối Tiên nghiệm

Mọi suy luận Bayesian đều bắt đầu từ chủ quan, trực giác, niềm tin của bản thân (các bên liên quan) hoặc dữ liệu thực nghiệm đã được nghiên cứu/biết đến của lĩnh vực đó - nói cách khác là 'chúng ta tin vào điều gì để bắt đầu'. Trong trường hợp loại kịch bản này, mô hình chứa trạng thái ban đầu của doanh nghiệp hoặc kinh nghiệm tích lũy trong một chiếc bình gọi là Phân phối Beta.

### 1.1 Định nghĩa Toán học

Phân phối Beta là hàm mật độ xác suất được tối ưu hóa để xử lý các giá trị xác suất từ 0 đến 1. Hàm được định nghĩa bằng công thức dưới đây. (Chi tiết về phân phối Beta được giải thích trong một bài viết khác giải phẫu phân phối Beta.)

$  $
f(x; \alpha, \beta) = \frac&#123;x^&#123;\alpha-1&#125;(1-x)^&#123;\beta-1&#125;&#125;&#123;B(\alpha, \beta)&#125;
$  $

Ở đây, mẫu số 

$  $
B(\alpha, \beta)
$  $

 là hàm Beta, một hằng số chuẩn hóa làm cho tổng xác suất bằng 1, và động lực cốt lõi là hai tham số 

$  $
\alpha
$  $

 và 

$  $
\beta
$  $

.

- 

$  $
\alpha
$  $

 (Alpha): Cường độ của bằng chứng tích lũy về thành công

- 

$  $
\beta
$  $

 (Beta): Cường độ của bằng chứng tích lũy về rủi ro hoặc thất bại

### 1.2 Diễn giải

Hãy nhìn vào cấu trúc của tử số 

$  $
x^&#123;\alpha-1&#125;(1-x)^&#123;\beta-1&#125;
$  $

 trong công thức. Khi 

$  $
\alpha
$  $

 càng lớn, tâm của phân phối di chuyển về phía 1 (thành công), và khi 

$  $
\beta
$  $

 càng lớn, nó di chuyển về phía 0 (thất bại).

Ở giai đoạn đầu kinh doanh, dựa trên thống kê thị trường, chúng ta có thể gán các giá trị như 

$  $
\alpha=2, \beta=8
$  $

. Điều này định hình 'kiến thức kinh nghiệm tiên nghiệm' rằng "cho đến nay, 2 trong số 10 lần đã thành công" thành một đường cong toán học.

Xác suất được tính bằng 

$  $
\alpha/(\alpha+\beta)
$  $

. Điều này cho phép chúng ta mô hình hóa kinh nghiệm, kiến thức tiên nghiệm hoặc trực giác về lĩnh vực thành các con số như "Tỷ lệ thành công, tỷ lệ lỗi, tỷ lệ phản hồi... là 20%". Ở đây, 2 và 8 đại diện cho cường độ của niềm tin; con số càng lớn thì niềm tin càng mạnh. Ví dụ, 20 và 80 có cùng tỷ lệ thành công 20% như 2 và 8, nhưng cường độ niềm tin lớn hơn nhiều.

$  $
\alpha
$  $

 và 

$  $
\beta
$  $

 là các siêu tham số (hyperparameters) mà chúng ta tự gán (hoặc đo lường từ dữ liệu hiệu suất trong quá khứ) để có thể mô hình hóa kiến thức tiên nghiệm. Các giá trị này được Động cơ Bayesian điều chỉnh thành giá trị thực tế khi dữ liệu (bằng chứng) tích lũy. Đây chính là điểm bắt đầu của quá trình theo dõi xem xác suất chủ quan phù hợp với dữ liệu thực tế đến mức nào.

Nói cách khác, điểm xuất phát của mô hình này là nó bắt đầu với trí tuệ sở hữu kinh nghiệm, chứ không phải ở trạng thái không có dữ liệu nào.

---

## 2. Tín hiệu từ Hiện trường: 'Phân phối Nhị thức' dưới dạng Hàm Likelihood

Các sự kiện xảy ra tại hiện trường bán hàng (cuộc họp, yêu cầu báo giá, v.v.) cuối cùng đều dẫn đến kết quả rời rạc: 'tín hiệu thành công' hoặc 'tín hiệu không thành công'. Công cụ nắm bắt điều này là Phân phối Nhị thức.

### 2.1 Định nghĩa Toán học

Xác suất thành công $ k $ lần khi một sự kiện có xác suất thành công $ p $ được thực hiện $ n $ lần như sau:

$  $
P(X=k) = &#123;n \choose k&#125; p^k (1-p)^&#123;n-k&#125;
$  $

Công thức này số hóa (Likelihood) 'sự thật (Evidence, bằng chứng)' nghe được từ hiện trường. 

$  $
p^k(1-p)^&#123;n-k&#125;
$  $

 đo lường mức độ khớp của xác suất p mà chúng ta giả định với kết quả thực tế $ k $. Hệ thống coi kết quả của mỗi bước do nhân viên kinh doanh nhập vào là phép thử nhị thức này, thay thế các tương tác thô bằng các tín hiệu toán học tinh chỉnh.

### 2.2 Trọng số Bằng chứng (Weight of Evidence, WoE)

Tại sao một số tín hiệu có trọng số cao trong khi những tín hiệu khác lại thấp?

Mô hình Bayesian được sử dụng trong tập này phản ánh khái niệm Trọng số Bằng chứng (WoE) - được Claude Shannon sử dụng trong Lý thuyết Thông tin và Alan Turing sử dụng trong giải mã - vào dữ liệu bằng chứng của hàm Likelihood (Phân phối Nhị thức).

Nó là logarit của Tỷ lệ Likelihood (Likelihood Ratio) giữa xác suất một tín hiệu xuất hiện trong nhóm 'thành công' và xác suất nó xuất hiện trong nhóm 'thất bại'. Lý do tại sao "đề cập đến đối thủ cạnh tranh ở giai đoạn đàm phán hợp đồng cuối cùng" là chí mạng vì Lượng thông tin thu được (Information Gain) khi tín hiệu đó xảy ra ở giai đoạn đó lớn hơn nhiều so với giai đoạn đầu.

Việc sử dụng trọng số thang log là kết quả của việc phản ánh toán học 'mật độ thông tin' này.

### 2.3 Diễn giải

Công thức này số hóa 'sự thật (Evidence)' từ hiện trường bằng cách phản ánh WoE. 

$  $
p^k(1-p)^&#123;n-k&#125;
$  $

 đo lường mức độ khớp của xác suất $ p $ mà chúng ta giả định với kết quả thực tế $ n $. Hệ thống coi kết quả của mỗi bước do nhân viên kinh doanh nhập vào là phép thử nhị thức này, thay thế các tương tác thô bằng các tín hiệu toán học tinh chỉnh.

---

## 3. Kết hợp Kiến thức: Phép màu của 'Tiên nghiệm Liên hợp (Conjugate Prior)'

Đỉnh cao của Động cơ Bayesian nằm ở quá trình cập nhật tạo ra 'sự chắc chắn của ngày mai' bằng cách cộng 'tín hiệu của hôm nay' vào 'kiến thức của hôm qua'.

### 3.1 Kết hợp Toán học (Posterior Update)

Theo định lý Bayes, xác suất Hậu nghiệm (Posterior) được tính như sau:

$  $
P(p|Data) \propto P(Data|p) \times P(p)
$  $

Lúc này, khi Phân phối Beta (Prior: kiến thức tiên nghiệm, niềm tin chủ quan) và Phân phối Nhị thức (Likelihood: dữ liệu bằng chứng) được kết hợp, một sự hài hòa toán học đáng kinh ngạc xảy ra. Quá trình toán học của sự kết hợp này sẽ được giải thích trong một bài viết riêng biệt giải phẫu phân phối Beta, nhưng công thức kết quả dưới đây có thể được xác nhận qua nhiều sách toán học.

$  $
P(p|k) = \frac&#123;p^&#123;(\alpha+k)-1&#125;(1-p)^&#123;(\beta+n-k)-1&#125;&#125;&#123;B(\alpha+k, \beta+n-k)&#125;
$  $

Nhìn vào kết quả, phân phối hậu nghiệm cũng trở thành một phân phối Beta với các tham số  và 

$  $
\beta' = \beta + (n-k)
$  $

, mang hình thức của phân phối Beta tiên nghiệm.

### 3.2 Sự thanh lịch của Giải pháp Giải tích (Analytical Solution)

Đây chính là sức mạnh của Tiên nghiệm Liên hợp (phân phối hậu nghiệm, kết hợp phân phối Beta chứa kiến thức tiên nghiệm và phân phối Nhị thức là phân phối dữ liệu bằng chứng, hội tụ trở lại thành phân phối Beta). Việc cập nhật được hoàn thành chỉ bằng cách cộng tín hiệu vào giá trị hiện có mà không cần các phép tính tích phân phức tạp. Trong thuật ngữ khoa học máy tính, đây là một phép toán thời gian hằng số với độ phức tạp tính toán là $ O(1) $. Đây là lý do tại sao hầu như không có tải máy chủ ngay cả khi xử lý hàng nghìn hoặc hàng chục nghìn đơn hàng trong thời gian thực - cơ sở cho mệnh đề "Việc tính toán nhẹ tựa lông hồng, nhưng kết quả nặng tựa đá tảng."

---

## 4. Biện minh Kỹ thuật: Tại sao là 'Mô hình Beta-Nhị thức' cho vấn đề này?

Giá trị kỹ thuật mà Deep Learning Bayesian và MCMC (Markov Chain Monte Carlo) sở hữu là tài sản cốt lõi của khoa học dữ liệu hiện đại. Tuy nhiên, mọi công cụ đều có nơi sử dụng tối ưu, nơi khả năng của nó có thể được tối đa hóa.

Ví dụ, khi tính toán xác suất nhập kho đúng hạn của Đơn đặt hàng (PO) thông qua Động cơ Bayesian Exa, mô hình mô phỏng MCMC rất hiệu quả. Điều này là do mô hình MCMC có khả năng tính toán lô (Batch) quy mô lớn và có thể phản ánh tinh vi không chỉ dữ liệu giao hàng bình thường trung bình mà còn cả dữ liệu được gọi là 'Ngoại lệ (Outlier)' như 'giao hàng chậm trễ'.

Cuối cùng, sự linh hoạt trong việc lựa chọn và áp dụng mô hình tối ưu theo các biến số phức tạp tại hiện trường là tối quan trọng, và tầm quan trọng của việc sử dụng mô hình đúng nơi đúng chỗ như vậy không thể được nhấn mạnh quá mức.

### 4.1 Vai trò của MCMC và Deep Learning Bayesian

MCMC xuất sắc trong việc xấp xỉ các phân phối xác suất nhiều chiều nơi hàng nghìn biến số đan xen. Bayesian dựa trên Deep Learning là cần thiết để trích xuất các mẫu phức tạp từ dữ liệu phi cấu trúc (hình ảnh, giọng nói, v.v.). Đây là những giải pháp mạnh mẽ tìm ra câu trả lời thông qua vô số mô phỏng và lấy mẫu.

$  $
A(x^*, x_t) = \min \left( 1, \frac&#123;P(x^*)g(x_t|x^*)&#125;&#123;P(x_t)g(x^*|x_t)&#125; \right)
$  $

(Công thức xác suất chấp nhận mẫu MCMC: Yêu cầu hàng chục nghìn lần lặp lại)

### 4.2 Điểm mạnh độc nhất của Mô hình Beta-Nhị thức

Ngược lại, trong các lĩnh vực có mục tiêu rõ ràng là 'thành công và thất bại' như dự đoán tỷ lệ thành công bán hàng, Giải pháp Giải tích (Analytical Solution) do mô hình Beta-Nhị thức cung cấp trở thành 'Tiêu chuẩn Vàng'.

- Thời gian thực: Phản hồi ngay lập tức là khả thi mà không cần lấy mẫu nặng nề.

- Khả năng giải thích: Có thể giải thích rõ ràng lý do tại sao xác suất thay đổi thông qua việc tăng hoặc giảm 

$  $
\alpha
$  $

 và 

$  $
\beta
$  $

.

Chúng tôi sẽ sử dụng Deep Learning và MCMC cho các vấn đề phức tạp hơn, nhưng tại điểm này, nơi yêu cầu ra quyết định kinh doanh nhanh chóng, chúng tôi đã chọn phương pháp rõ ràng và thanh lịch nhất này.

---

## 5. Cuộc cách mạng Kiến trúc: Ước lượng Bayesian Đệ quy (Recursive Bayesian Estimation)

Trong kỷ nguyên bùng nổ dữ liệu, việc tải lại 'tất cả dữ liệu trong quá khứ' mỗi lần là không hiệu quả. Động cơ của mô hình này áp dụng kiến trúc Đệ quy (Recursive) tập trung vào 'tinh hoa của thông tin'.

Đây là gốc rễ sâu nhất của mô hình này:

Tất cả nhật ký cuộc họp trong quá khứ đã được nén hoàn hảo (Compression) thành chỉ hai con số, 

$  $
\alpha
$  $

 và 

$  $
\beta
$  $

, của trạng thái hiện tại (phân phối hậu nghiệm được cập nhật bởi sự kết hợp của kiến thức tiên nghiệm và bằng chứng dữ liệu). Khi một tín hiệu mới xuất hiện, hệ thống chỉ cần cộng tín hiệu vào trạng thái hiện tại thay vì lục lọi các nhật ký trong quá khứ.

Nguyên lý Điều chỉnh Quỹ đạo của NASA và Hiệu chỉnh Vị trí Thời gian thực của Xe tự lái

Lý thuyết này chia sẻ cùng một dòng dõi toán học với Bộ lọc Kalman (Kalman Filter), vốn theo dõi vị trí của tàu vũ trụ trong chương trình Apollo của NASA như một kỹ thuật suy luận trạng thái trong thời gian thực bất cứ khi nào dữ liệu đến một cách tuần tự.

Thống kê truyền thống bắt đầu phân tích "sau khi tất cả dữ liệu được thu thập", nhưng Bayesian Đệ quy đưa ra phán đoán "ngay khi thông tin xuất hiện". Đây là thuật toán nghiêm ngặt nhất để quản lý sự không chắc chắn trong môi trường ERP nơi tính thời gian thực là sự sống còn.

---

### Khi Toán học trở thành Công cụ cho Kinh doanh

Thông qua [Phụ lục Phần 1], chúng ta đã thấy trật tự toán học ẩn dưới tảng băng trôi khổng lồ của Động cơ Bayesian.

- Phân phối Beta là chiếc bình chứa kinh nghiệm của bạn.

- Phân phối Nhị thức là bộ lọc chấp nhận các tín hiệu nóng hổi từ hiện trường.

- Và thông qua phước lành của Tiên nghiệm Liên hợp, hệ thống rút ra sự chắc chắn chính xác nhất theo cách nhẹ nhàng nhất.

Đây không phải là một công cụ thống kê đơn giản. Nó là một 'La bàn Ra quyết định' theo dõi và dẫn dắt doanh nghiệp của bạn một cách tinh vi như quỹ đạo tàu vũ trụ.

[Teaser Tiếp theo: Phần 2]

Tại sao xác suất lại giảm vào những ngày 'Im lặng' khi không có dữ liệu nào đến?

Lần tới, đã đến lúc kiểm tra bên trong của 'Nghịch lý của Sự im lặng và Trọng số Log' từ góc độ của Lý thuyết Thông tin.
