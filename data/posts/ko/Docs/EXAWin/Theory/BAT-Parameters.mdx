---
title: '베이지안 적용: 파라미터 교정과 자동 최적화'
date: '2026-02-20'
order: 2
section: 'EXAWin'
sectionOrder: 1
subSectionOrder: 2
tags: ['Guide', 'EXAWin', 'Bayesian', 'Parameters', 'f-coupling', 'Auto-Tuner']
draft: false
public: true
summary: '시그널 Impact의 교정 원칙(f-coupling), EPR 가드레일, 그리고 데이터 성숙도에 따른 6단계 자동 파라미터 최적화(BAT) 시스템을 해설한다.'
---

[이전 편: Prior α/β 설정 원리](https://www.exaeuler.com/ko/posts/ko/Docs/EXAWin/Theory/BAT-byesian-priorAlphaBeta)에서 사전 확률의 설정과 학습 로드맵을 다루었다. 본 글은 그 다음 질문에 답한다: **시그널의 크기(Impact)는 어떻게 정하고, 시스템은 어떻게 스스로 최적화하는가?**

엔진의 수식이 아무리 정교해도, **그 수식에 넣는 숫자가 엉뚱하면 엉뚱한 답이 나온다.** 자동차 엔진이 아무리 정밀해도 연료의 옥탄가가 맞지 않으면 노킹이 발생하는 것과 같다. 이 글은 EXAWin의 베이지안 엔진에 **올바른 연료를 넣는 원칙**과, 시스템이 데이터를 축적하며 **스스로 연료를 조절하는 메커니즘**에 대한 이야기다.

<br/>
---

## 1장. 우도 없는 세계: Pseudo-Count 접근법

### 1.1 솔직한 출발점

표준 베이지안에서 업데이트는 우도함수 $P(D \mid \theta)$를 통해 이루어진다. 그러나 영업 시그널 — **"고객 반응이 긍정적이었다"**, **"결정권자가 우리 쪽으로 기울었다"** — 은 수학적으로 정의된 확률 분포에서 추출된 관측이 아니다.

EXAWin은 이 한계를 **가상 관측치(pseudo-count)** 접근법으로 해결한다:

$$
\alpha_{\text{new}} = \alpha_{\text{prev}} + \text{SWV} \times \text{Impact}
$$

이것은 **"이 시그널은 SWV × Impact 회의 가상 성공 관측과 동등한 증거적 무게를 가진다"**고 선언하는 것이다. 베타 분포는 $\alpha, \beta > 0$인 모든 실수에 대해 유효하므로, pseudo-count가 정수일 필요가 없다.

이 방법론은 통계학에서 **전문가 판단 도출(expert elicitation)**이라는 이름으로 확립되어 있다 (O'Hagan et al., 2006). 전문가가 "이 증거는 직접 관측 N회와 동등하다"고 평가할 때, N을 pseudo-count로 $\alpha$ 또는 $\beta$에 가산하는 것은 정당화된 방법론이다.

**핵심 질문은: 그 N을 어떻게 정하는가?**

<br/>
---

## 2장. f-Coupling: 시그널과 Prior의 척도를 맞추다

### 2.1 독립적 스케일의 위험

Prior($\alpha_0=2, \beta_0=8$, 강도 $S=10$)과 시그널 Impact가 독립적으로 설정되면, **단일 시그널이 기업의 전체 과거 경험을 한 순간에 압도하는** 비현실적 상황이 발생할 수 있다.

### 2.2 Evidence Fraction ($f$)

해결책은 시그널의 Impact를 **Prior 강도의 분수(fraction)**로 정의하는 것이다:

$$
\text{Impact}_i = f_i \times S \quad \text{where } S = \alpha_0 + \beta_0
$$

$f_i$는 **"이 시그널 1회가 기업의 사전 경험 전체의 몇 퍼센트에 해당하는 증거인가?"**를 나타내는 비율이다.

| 시그널 유형 | $f$ | Impact ($S=10$) | 해석 |
| --- | --- | --- | --- |
| **Game Changer** | 0.50 | **5.0** | 사전 경험의 절반만큼 강한 단일 증거 |
| **Strong Affirmation/Negation** | 0.10 | **1.0** | 사전 경험의 10% — 명확한 시그널 |
| **Weak Affirmation/Negation** | 0.04 | **0.4** | 사전 경험의 4% — 미세한 힌트 |
| **No Signal** | 0.01 | **0.1** | 거의 노이즈 수준 |

### 2.3 스케일 불변성

이 커플링의 핵심 성질: **$f$가 동일하면, Prior 강도 $S$에 관계없이 P(Win)의 궤적이 완전히 동일하다.** $\alpha_0 = rS$, $\beta_0 = (1-r)S$로 놓으면 $S$가 약분되어 $f$만의 함수가 된다. $S=10$이든 $S=100$이든 동일한 학습 궤적 — 이것이 커플링의 존재 이유다.

### 2.4 EPR 가드레일

**Evidence-Prior Ratio (EPR)**는 1회 미팅의 최대 증거가 Prior를 얼마나 흔드는지를 진단하는 지표다:

$$
\text{EPR} = \frac{\text{SWV}_{\max} \times \text{Impact}}{S}
$$

EXAWin은 **코드 레벨에서** EPR 상한을 강제한다:

| 시그널 유형 | EPR 상한 | 최대 Impact ($S=10$) | 설계 근거 |
| --- | --- | --- | --- |
| **Game Changer** | 2.0 | 7.7 | 의도적 압도 허용, 그러나 200%를 넘길 수는 없음 |
| **일반 시그널** | 0.5 | 1.9 | Prior의 50% 이내로 제한 |

사용자가 Signal Master에서 Impact 값을 변경할 때, 이 상한을 초과하면 **저장이 거부**된다. 이것은 경험 부족한 사용자가 파라미터를 극단적으로 설정하여 시스템을 불안정하게 만드는 것을 방지하는 안전장치다.

<br/>
---

## 3장. 의사결정 임피던스: 확률에서 행동으로

### 3.1 임피던스 공식

$$
I = \frac{1}{1 + \exp\bigl(-k \cdot (P(\text{Win}) - T)\bigr)}
$$

- **$T$** = 임계값 — 각 스테이지에서 "이 딜이 통과해야 할 최소 기준"
- **$k$** = 기울기 — 임계점 근처에서의 판별 민감도

### 3.2 스테이지별 기본 파라미터

| Stage | SWV | $T$ | $k$ | 설계 의도 |
| --- | --- | --- | --- | --- |
| Discovery | 1.00 | 0.35 | 5 | 낮은 기준, 관대한 탐색 |
| Qualification | 1.69 | 0.40 | 7 | 자격 검증, 기본 기준 |
| Solution-Fit | 2.10 | 0.45 | 7 | 적합성 확인 |
| Proposal | 2.39 | 0.50 | 12 | 비용 투입 — **날카로운 판별** |
| Negotiation | 2.61 | 0.55 | 11 | 최종 관문, 가장 엄격 |

$T$는 스테이지가 진행될수록 증가한다. "Discovery에서 P(Win)=30%면 탐색을 계속하라. 하지만 Proposal까지 왔는데 여전히 40%라면 진지한 재고가 필요하다."

$k$는 판별 민감도를 결정한다. Proposal($k=12$)에서는 P(Win)이 $T=0.50$ 아래인지 위인지에 따라 임피던스가 급격히 갈린다 — **본격적 비용 투입 단계에서 애매함을 허용하지 않겠다**는 설계 철학이다.

<br/>
---

## 4장. Auto-Tuner: 엔진이 스스로 연료를 조절하는 법

### 4.1 데이터 성숙도 Phase — "기록이 충분한가?"

Auto-Tuner의 첫 번째 질문은 단순하다: **"이 회사에 끝난 프로젝트가 몇 건인가?"**

Why 끝난 프로젝트? — 아직 진행 중인 딜은 "이 설정이 맞았는지 틀렸는지"를 검증할 수 없다. 축구 경기 전반전에 감독 전술을 평가할 수 없는 것과 같다. **결과가 나온 경기(Won/Lost)만이 전술 수정의 근거가 된다.**

핵심: **Won과 Lost 중 적은 쪽(min)이 전체 신뢰 등급을 결정한다.** Won이 50건이어도 Lost가 3건이면, Lost 패턴을 학습할 근거가 부족하기 때문이다.

| 등급 | Won | Lost | 합계 | 적용 범위 | 학습 신뢰도 |
| --- | --- | --- | --- | --- | --- |
| ❌ **불가** | < 5 | < 5 | < 10 | 분석 자체 불가 | 데이터 부족 |
| 🟠 **최소** | 5~9 | 5~9 | 10~19 | 표시만 (Apply 잠금) | 방향성 참조만, 과적합 위험 |
| 🟡 **보통** | 10~19 | 10~19 | 20~39 | Impact, T, k | 주요 파라미터 조정 가능 |
| 🟢 **양호** | 20~49 | 20~49 | 40~99 | 전체 (Dampening, Silence 포함) | 대부분 파라미터 신뢰도 높음 |
| 🔵 **우수** | 50+ | 50+ | 100+ | 전체 + 통계적 안정 | Grid Search 수렴, 완전 자동화 가능 |

### 4.2 Auto-Tuner가 하는 일 — "과거 시합 기록을 분석하는 코치"

Auto-Tuner를 이해하는 가장 좋은 비유는 **스포츠 코치의 경기 분석**이다 — 이제부터 모든 설명을 이 비유로 풀겠다.

당신의 회사가 지금까지 25개의 프로젝트를 끝냈다. 10건을 따고 15건을 졌다. Auto-Tuner는 이 **25경기의 기록**을 꺼내 놓고, "우리 팀의 전술(파라미터)이 최적이었는가?"를 하나씩 점검한다.

<br/>

#### ① "우리 팀의 기본 실력은 얼마인가?" — Prior 추천

**질문**: "우리가 기본적으로 이길 확률은 몇 %인가?"

시스템 설정: 현재 Prior = α 2, β 8 → 기본 성공률 **20%**. 하지만 실제 25개 프로젝트 결과를 보니, 10건을 따서 성공률은 **40%**. 시스템이 말한다:

> "당신 팀의 실제 성공률은 40%에 가깝습니다. 출발선을 20%로 잡으면, 매번 처음 3~4회 미팅은 '아직 확률이 낮아요'만 반복하게 됩니다. **출발선을 올려볼까요?**"

단, 이 값은 **자동 적용하지 않는다.** Prior는 "우리 팀의 기본 역량"에 대한 경영진의 **전략적 판단**이기 때문이다. "40%까지 올리면 자만할 수 있고, 25%로 보수적으로 잡는 것도 전략"이라면 — 그것은 코치(시스템)가 아니라 감독(경영진)이 결정할 몫이다.

<br/>

#### ② "어떤 시그널이 진짜 의미 있었나?" — Signal Lift

**질문**: "우리가 기록한 시그널 중, 실제로 성공과 관련 있었던 건 뭔가?"

시스템이 25개 프로젝트의 시그널을 꺼내서 비교한다:

| 시그널 | Won에서 출현 | Lost에서 출현 | **Lift** | 해석 |
| --- | --- | --- | --- | --- |
| "기술적 적합성 확인" | Won 10건 중 8건 | Lost 15건 중 3건 | **4.0** | ✅ 이 시그널이 나온 딜은 **4배 더 잘 됐다** |
| "예산 확보 확인" | 6건 | 4건 | 2.3 | 의미 있음 |
| "경쟁사 존재 확인" | 7건 | 10건 | 1.1 | ❌ 별 차이 없음 |

Lift가 1보다 크면: **"이 시그널이 나타난 딜은 실제로 더 잘 됐다."**
Lift가 1에 가까우면: **"이 시그널은 성공과 별 상관이 없었다."**

이 정보는 영업팀에게 **"어떤 시그널을 더 주의 깊게 포착해야 하는지"**를 알려준다.

<br/>

#### ③ "시그널의 무게가 적절했나?" — Impact 교정

**질문**: "Strong Affirmation에 1.0점을 줬는데, 실제로는 0.7이 더 맞지 않았을까?"

시스템이 Impact 값을 **0.1부터 10.0까지** 하나씩 바꿔보면서 시뮬레이션한다:

- "Strong을 0.5로 낮추면 — Won과 Lost의 P(Win)이 너무 겹친다 (판별 안 됨)."
- "Strong을 1.0으로 두면 — Won 평균 P(Win)=55%, Lost 평균=30%. **분리가 잘 된다.**"
- "Strong을 2.0으로 올리면 — Won이 70%까지 가지만, Lost도 45%까지 올라온다 (과잉 반응)."

가장 **Won과 Lost가 깔끔하게 갈라지는** Impact 값을 찾아서 추천한다. 의사가 혈액검사 수치를 보고 "정상/비정상의 기준을 어디 둬야 가장 정확한 진단이 되는가?"를 찾는 것과 같은 원리다.

<br/>

#### ④ "합격선을 어디에 긋나?" — 임계값 $T$ 최적화

**질문**: "Discovery 단계에서 T=0.35 — 이 기준이 너무 관대했나, 너무 엄격했나?"

시스템이 과거 데이터로 검증한다:

- T=0.25로 낮추면: Won은 전부 통과하지만, Lost도 대부분 통과 → **"합격선이 너무 낮아서 불합격 딜도 다 통과시킴"**
- T=0.35로 두면: Won의 80%가 통과, Lost의 70%가 탈락 → **"적정 수준"**
- T=0.50으로 올리면: Lost는 거의 탈락하지만, Won도 절반이 탈락 → **"합격선이 너무 높아서 좋은 딜도 걸러냄"**

**시험의 커트라인을 정하는 것**과 같다. "커트라인을 너무 낮추면 실력 없는 학생도 합격하고, 너무 올리면 괜찮은 학생도 떨어진다." 최적 커트라인은 **합격자 중 실제 우수자 비율과 불합격자 중 실제 부적격자 비율을 동시에 최대화**하는 지점이다.

<br/>

#### ⑤ "판별을 얼마나 칼같이 할 것인가?" — 기울기 $k$ 조정

**질문**: "합격선(T) 근처에서 시스템이 얼마나 민감하게 반응해야 하는가?"

$k$가 작으면: P(Win)이 T 근처일 때 "아직 애매합니다"라고 부드럽게 판단. **초기 스테이지에 적합** — 탐색 중이니까.

$k$가 크면: P(Win)이 T보다 조금만 낮아도 "🔴 위험"으로 급격히 판정. **Proposal이나 Negotiation에 적합** — 돈을 쓰기 시작한 단계에서 "글쎄요..."는 허용되지 않으니까.

시스템은 각 스테이지에 쌓인 **증거의 양**(미팅 횟수, 시그널 수)을 보고 k를 조정한다. 증거가 많이 쌓인 후반 스테이지에서는 더 칼같이, 증거가 적은 초반에서는 더 관대하게.

<br/>

#### ⑥ "세부 조절" — 감쇄와 침묵 페널티 (Phase 3 전용)

이 두 파라미터는 Phase 3(30건 이상)에서만 조정된다. 데이터가 충분해야 의미 있는 미세 조정이 가능하기 때문이다.

**감쇄(Dampening)**: 한 번 미팅에서 시그널 3개가 동시에 나왔을 때, 가장 강한 시그널만 100% 반영하고 나머지는 25%만 반영한다. 이 25%라는 비율이 최적인지를 과거 데이터로 검증한다.

**침묵 페널티(Silence Penalty)**: 고객이 2주 이상 연락이 없으면 β가 조금씩 증가하여 P(Win)이 하락한다. "소식이 없으면 나쁜 소식"이라는 영업 격언의 수학적 구현인데, **그 페널티의 크기가 적절한지**를 과거 데이터로 검증한다. 실제로 침묵 후 Lost가 된 프로젝트가 많았다면 페널티를 높이고, 침묵 후에도 Won이 된 경우가 많았다면 페널티를 낮춘다.

### 4.3 "적용하면 뭐가 달라지나?" — Impedance Impact 시뮬레이션

추천 버튼을 누르기 전, 관리자가 가장 궁금한 것: **"이걸 바꾸면 우리 딜들의 점수가 어떻게 변하는가?"**

Impedance Impact 테이블은 이 질문에 답한다:

| Stage | P(Win) | **현재 임피던스** | **추천 적용 시** | **변화** | 건수 |
| --- | --- | --- | --- | --- | --- |
| Discovery | 21.5% | 28.4% | 53.5% | ↑ 25.1%p | 15 |
| Qualification | 31.7% | 30.7% | 60.3% | ↑ 29.6%p | 15 |
| Proposal | 46.4% | 40.8% | 74.0% | ↑ 33.4%p | 15 |

"현재 설정에서 Discovery 평균 임피던스가 28%인데, 추천 T/k를 적용하면 54%로 올라간다." 이것은 **추천 설정이 Won 딜과 Lost 딜을 더 잘 구분해낸다**는 의미다. 변화가 클수록, 현재 설정이 최적에서 멀었다는 뜻이다.

<br/>
---

## 5장. 시그널 체계의 전체 지도

### 5.1 Impact Types

| 순서 | 유형 | 타입 | Impact | f | 해석 |
| --- | --- | --- | --- | --- | --- |
| 1 | Game Changer | α 증가 | 5.0 | 0.50 | 결정적 긍정 단일 증거 |
| 5 | Strong Affirmation | α 증가 | 1.0 | 0.10 | 명확한 긍정 시그널 |
| 10 | Weak Affirmation | α 증가 | 0.4 | 0.04 | 미세한 긍정 힌트 |
| 15 | No Signal | 중립 | 0.1 | 0.01 | 노이즈 수준 |
| 20 | Weak Negation | β 증가 | 0.4 | 0.04 | 미세한 부정 힌트 |
| 25 | Strong Negation | β 증가 | 1.0 | 0.10 | 명확한 부정 시그널 |
| 30 | Game Changer (Negative) | β 증가 | 5.0 | 0.50 | 결정적 부정 단일 증거 |

**대칭 구조**: 긍정과 부정이 동일한 f-스케일로 대칭. Game Changer Negative는 "경쟁사 확정", "예산 전액 삭감"과 같은 **치명적 부정 시그널**에 해당한다.

### 5.2 f-Coupling이 보장하는 것

1. **스케일 불변성**: Prior 강도가 바뀌어도 학습 궤적 동일
2. **EPR 가드레일**: 단일 시그널의 과도한 영향 코드 레벨 차단
3. **대칭성**: 긍정·부정 동일 척도 — "동일 강도의 증거는 동일 크기의 효과"
4. **해석 가능성**: 모든 값이 "Prior의 몇 %"로 설명 가능

<br/>
---

## 참고 문헌

1. **O'Hagan, A., Buck, C.E., Daneshkhah, A., et al. (2006)**. *Uncertain Judgements: Eliciting Experts' Probabilities*. Wiley. — 전문가 판단 도출 및 pseudo-count 방법론.
2. **Ibrahim, J.G. & Chen, M.H. (2000)**. "Power prior distributions for regression models." *Statistical Science*, 15(1), 46-60. — Evidence Discounting.
3. **Youden, W.J. (1950)**. "Index for rating diagnostic tests." *Cancer*, 3(1), 32-35. — 임계값 최적화의 통계적 근거.
4. **Cooper, R.G. (2008)**. "Perspective: The Stage-Gate Idea-to-Launch Process." *JPIM*, 25(3). — Stage-Gate 의사결정 프로세스.

---
